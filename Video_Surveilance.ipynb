{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNN20q1M4UELEo3z/atEQ+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackhawkee/opencv-flask/blob/main/Video_Surveilance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # !pip install glob\n",
        "# !mkdir train\n",
        "# !pwd\n",
        "# !wget http://www.cse.cuhk.edu.hk/leojia/projects/detectabnormal/Avenue_Dataset.zip /content/train/\n",
        "# !wget http://www.cse.cuhk.edu.hk/leojia/projects/detectabnormal/ground_truth_demo.zip /content/train/\n",
        "# %cd /content/train/\n",
        "# !mv /content/ground_truth_demo.zip /content/train/ground_truth_demo.zip\n",
        "# !unzip Avenue_Dataset.zip\n",
        "# ! rm -rf /content/train/frames/*.jpg\n",
        "!cp /content/train/Avenue\\ Dataset/testing_videos/12.avi /content/train/12_test.avi\n"
      ],
      "metadata": {
        "id": "-gX2TO8etJB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr_ovHY4s7qv"
      },
      "outputs": [],
      "source": [
        "# from keras.preprocessing.image import img_to_array,load_img\n",
        "from tensorflow.keras.utils import img_to_array,load_img\n",
        "import numpy as np\n",
        "import glob\n",
        "import os \n",
        "import cv2\n",
        "\n",
        "from keras.layers import Conv3D,ConvLSTM2D,Conv3DTranspose\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import imutils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store_image=[]\n",
        "%cd /content/\n",
        "!pwd\n",
        "# train_path='./train'\n",
        "train_path='/content/train'\n",
        "print(train_path)\n",
        "fps=5\n",
        "train_videos=os.listdir(train_path)\n",
        "train_images_path=train_path+'/frames'\n",
        "os.makedirs(train_images_path)\n",
        "\n",
        "# def store_inarray(image_path):\n",
        "#     image=load_img(image_path)\n",
        "#     image=img_to_array(image)\n",
        "#     image=cv2.resize(image, (227,227), interpolation = cv2.INTER_AREA)\n",
        "#     gray=0.2989*image[:,:,0]+0.5870*image[:,:,1]+0.1140*image[:,:,2]\n",
        "#     store_image.append(gray)"
      ],
      "metadata": {
        "id": "WRKKaBzStn5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_image=[]\n",
        "%cd /content/\n",
        "!pwd\n",
        "# train_path='./train'\n",
        "train_path='/content/train/'\n",
        "print(train_path)\n",
        "fps=5\n",
        "# train_videos=os.listdir(train_path)\n",
        "train_videos=os.listdir(train_path+'/Avenue Dataset/training_videos')\n",
        "train_images_path=train_path+'/frames'\n",
        "# os.makedirs(train_images_path)\n",
        "\n",
        "def store_inarray(image_path):\n",
        "    image=load_img(image_path)\n",
        "    image=img_to_array(image)\n",
        "    image=cv2.resize(image, (227,227), interpolation = cv2.INTER_AREA)\n",
        "    gray=0.2989*image[:,:,0]+0.5870*image[:,:,1]+0.1140*image[:,:,2]\n",
        "    store_image.append(gray)\n",
        "\n",
        "# print('train_videos >> ', train_videos)\n",
        "for video in train_videos:\n",
        "    # os.system( 'ffmpeg -i {}/{} -r 1/{}  {}/frames/%03d.jpg'.format(train_path,video,fps,train_path))\n",
        "    # print('within video for loop >>>>>>> ', video,fps,train_path)\n",
        "    os.system( 'ffmpeg -i {}/{} -r 1/{}  {}/frames/%03d.jpg'.format('/content/train/Avenue\\ Dataset/training_videos',video,fps,train_path))\n",
        "    images=os.listdir(train_images_path)\n",
        "    train_path='/content/train'\n",
        "    train_images_path=train_path+'/frames'\n",
        "    for image in images:\n",
        "        image_path=train_images_path + '/' + image\n",
        "        print(image_path)\n",
        "        store_inarray(image_path)\n",
        "\n",
        "# print('List >>>>>>', store_image)\n",
        "\n",
        "store_image=np.array(store_image)\n",
        "a,b,c=store_image.shape\n",
        "\n",
        "store_image.resize(b,c,a)\n",
        "store_image=(store_image-store_image.mean())/(store_image.std())\n",
        "store_image=np.clip(store_image,0,1)\n",
        "np.save('training.npy',store_image)        "
      ],
      "metadata": {
        "id": "z7bqYlLmxUP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stae_model=Sequential()\n",
        "\n",
        "stae_model.add(Conv3D(filters=128,kernel_size=(11,11,1),strides=(4,4,1),padding='valid',input_shape=(227,227,10,1),activation='tanh'))\n",
        "stae_model.add(Conv3D(filters=64,kernel_size=(5,5,1),strides=(2,2,1),padding='valid',activation='tanh'))\n",
        "stae_model.add(ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,padding='same',dropout=0.4,recurrent_dropout=0.3,return_sequences=True))\n",
        "stae_model.add(ConvLSTM2D(filters=32,kernel_size=(3,3),strides=1,padding='same',dropout=0.3,return_sequences=True))\n",
        "stae_model.add(ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,return_sequences=True, padding='same',dropout=0.5))\n",
        "stae_model.add(Conv3DTranspose(filters=128,kernel_size=(5,5,1),strides=(2,2,1),padding='valid',activation='tanh'))\n",
        "stae_model.add(Conv3DTranspose(filters=1,kernel_size=(11,11,1),strides=(4,4,1),padding='valid',activation='tanh'))\n",
        "\n",
        "stae_model.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ODkNz1xU2cvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data=np.load('/content/training.npy')\n",
        "frames=training_data.shape[2]\n",
        "frames=frames-frames%10\n",
        "\n",
        "training_data=training_data[:,:,:frames]\n",
        "training_data=training_data.reshape(-1,227,227,10)\n",
        "training_data=np.expand_dims(training_data,axis=4)\n",
        "target_data=training_data.copy()\n",
        "\n",
        "epochs=5\n",
        "batch_size=1\n",
        "\n",
        "callback_save = ModelCheckpoint(\"saved_model.h5\", monitor=\"mean_squared_error\", save_best_only=True)\n",
        "\n",
        "callback_early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "stae_model.fit(training_data,target_data, batch_size=batch_size, epochs=epochs, callbacks = [callback_save,callback_early_stopping])\n",
        "stae_model.save(\"saved_model.h5\")"
      ],
      "metadata": {
        "id": "2dId9Zxw2oM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Test.py"
      ],
      "metadata": {
        "id": "Z8d961X54GiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "import cv2\n",
        "import numpy as np \n",
        "from keras.models import load_model\n",
        "import argparse\n",
        "from PIL import Image\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "def mean_squared_loss(x1,x2):\n",
        "    difference=x1-x2\n",
        "    a,b,c,d,e=difference.shape\n",
        "    n_samples=a*b*c*d*e\n",
        "    sq_difference=difference**2\n",
        "    Sum=sq_difference.sum()\n",
        "    distance=np.sqrt(Sum)\n",
        "    mean_distance=distance/n_samples\n",
        "\n",
        "    return mean_distance\n",
        "\n",
        "\n",
        "model=load_model(\"/content/saved_model.h5\")\n",
        "\n",
        "# cap = cv2.VideoCapture(\"__path_to_custom_test_video\")\n",
        "cap = cv2.VideoCapture(\"/content/train/12_test.avi\")\n",
        "!echo $pwd\n",
        "print(cap.isOpened())\n",
        "\n",
        "while cap.isOpened():\n",
        "    imagedump=[]\n",
        "    ret,frame=cap.read()\n",
        "\n",
        "    for i in range(10):\n",
        "        ret,frame=cap.read()\n",
        "        # if frame is None:\n",
        "        #   break\n",
        "        image = imutils.resize(frame,width=700,height=600)\n",
        "\n",
        "        frame=cv2.resize(frame, (227,227), interpolation = cv2.INTER_AREA)\n",
        "        gray=0.2989*frame[:,:,0]+0.5870*frame[:,:,1]+0.1140*frame[:,:,2]\n",
        "        gray=(gray-gray.mean())/gray.std()\n",
        "        gray=np.clip(gray,0,1)\n",
        "        imagedump.append(gray)\n",
        "    \n",
        "    # print('imagedump >>>> ', imagedump)\n",
        "\n",
        "    imagedump=np.array(imagedump)\n",
        "\n",
        "    imagedump.resize(227,227,10)\n",
        "    imagedump=np.expand_dims(imagedump,axis=0)\n",
        "    imagedump=np.expand_dims(imagedump,axis=4)\n",
        "\n",
        "    output=model.predict(imagedump)\n",
        "\n",
        "    loss=mean_squared_loss(imagedump,output)\n",
        "\n",
        "    if frame.any()==None:\n",
        "        print(\"none\")\n",
        "\n",
        "    ret,frame=cap.read()\n",
        "    image = imutils.resize(frame,width=700,height=600)\n",
        "\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
        "        break\n",
        "    if loss>0.00068:\n",
        "        print('Abnormal Event Detected')\n",
        "        # cv2.putText(image,\"Abnormal Event\",(100,80),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,255),4)\n",
        "        cv2.putText(image,\"Abnormal Event\",(100,80),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,255),4)\n",
        "\n",
        "    # cv2.imshow(\"video\",image)\n",
        "    cv2_imshow(image)\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "M63AKAIF4Cye"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}